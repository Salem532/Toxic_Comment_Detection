# Toxic_Comment_Detection
An NLP-based deep learning project to accurately identify toxic comments across 6 categories, using Word2Vec embeddings and a Bi-LSTM architecture. Achieving a high ROC-AUC of 0.97+.

ğŸ‘‰ Project Development Pitfalls & Detailed Analysis: [æ·±åº¦å­¦ä¹ æ–°æ‰‹è¸©å‘å®å½•](https://zhuanlan.zhihu.com/p/2001126552239370558)

## ğŸŒŸ Key Features

Modular Design: Separated configs, data processing, model, and training logic for high maintainability.

Robust Preprocessing: Custom cleaning pipeline for noisy web comments (handling OOV, tokenization, and padding).

Word2Vec + Bi-LSTM: Combines semantic word vectors with bidirectional context capturing.

Evaluation Toolkit: Includes AUC/F1 reporting and T-SNE visualization of word embeddings.

## ğŸ› ï¸ 1. Environment Setup

``` bash
# 1. create and activate conda environment
conda create -n comment_det python=3.9 -y
conda activate comment_det

# 2. install dependencies
pip install -r requirements.txt
```

## ğŸ“Š 2. Dataset Preparation

Download the dataset from Kaggle's [Toxic Comment Classification](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data).

Place the dataset in the following structure (root directory named `data/raw/`)

``` text
data/raw/
â”œâ”€â”€ train.csv          # train set, includes comments and labels
â”œâ”€â”€ test.csv           # test set, includes comments
â”œâ”€â”€ test_labels.csv    # test set labels (for validation only)
â””â”€â”€ sample_submission.csv  # sample submission file
```

## ğŸš€ 3. Usage

``` bash
# Train the model with default config.yaml
python train.py

# Visualize Word2Vec embeddings via T-SNE
python visualize.py

# Run full evaluation on the test set
python evaluate.py

# Predict toxicity for a specific comment
python predict.py --text "I need to kill this process."
```


## ğŸ¤ Contributing

Feel free to open issues or pull requests. If this project helped you, please give it a Star â­ï¸!

